{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Problem Definition & Objective\n",
                "\n",
                "### Selected project track\n",
                "**Project Track:** Artificial Intelligence & Machine Learning (Recommendation Systems)\n",
                "\n",
                "### Clear problem statement\n",
                "In the digital age, readers are overwhelmed by the vast number of books available. Finding a book that matches one's specific interests can be time-consuming and frustrating. Users often rely on general popularity lists which may not align with their personal taste. The problem is to build a system that can filter through thousands of books and suggest titles that are most relevant to a user based on a book they already like.\n",
                "\n",
                "### Real-world relevance and motivation\n",
                "Recommendation systems are ubiquitous in modern tech (Netflix, Amazon, Spotify). A personalized book recommender improves user engagement, increases sales for retailers, and helps readers discover hidden gems they might have missed. This project demonstrates how Content-Based Filtering can be used to solve this information overload problem."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Understanding & Preparation\n",
                "\n",
                "### Dataset source\n",
                "We are using a subset of the **Book-Crossing Dataset**. \n",
                "- **Source:** Publicly available dataset.\n",
                "- **Files:** `BX-Books.csv` (contains Title, Author, Publisher, etc.).\n",
                "\n",
                "### Data loading and exploration\n",
                "We will load the dataset and inspect its structure."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Load the books data\n",
                "# Using 'on_bad_lines' to skip any malformed rows in the CSV\n",
                "try:\n",
                "    books_df = pd.read_csv('data/BX-Books.csv', sep=';', encoding='latin-1', on_bad_lines='skip', low_memory=False)\n",
                "    print(\"Dataset loaded successfully.\")\n",
                "    print(f\"Initial shape: {books_df.shape}\")\n",
                "except FileNotFoundError:\n",
                "    print(\"Error: 'data/BX-Books.csv' not found. Please ensure the data directory exists.\")\n",
                "\n",
                "# Display first few rows\n",
                "books_df.head(3)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Cleaning, preprocessing, feature engineering\n",
                "We need to handle missing values and create a unified text feature for our model. The core idea is to combine **Title**, **Author**, and **Publisher** into a single string (bag of words) that describes the book."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Select relevant columns\n",
                "books_df = books_df[['Book-Title', 'Book-Author', 'Publisher']]\n",
                "\n",
                "# 2. Handling missing values (fill with empty string)\n",
                "books_df = books_df.fillna('')\n",
                "\n",
                "# 3. Feature Engineering: Combine columns\n",
                "books_df['features'] = books_df['Book-Title'] + \" \" + books_df['Book-Author'] + \" \" + books_df['Publisher']\n",
                "\n",
                "# 4. Preprocessing: Convert to lowercase to ensure consistency\n",
                "books_df['features'] = books_df['features'].apply(lambda x: x.lower())\n",
                "\n",
                "print(\"Feature engineering complete. Example feature:\")\n",
                "print(books_df['features'].iloc[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model / System Design\n",
                "\n",
                "### AI technique used\n",
                "We are using **Content-Based Filtering** with **Natural Language Processing (NLP)** techniques.\n",
                "\n",
                "### Architecture or pipeline explanation\n",
                "1.  **Input:** User provides a book title they like.\n",
                "2.  **Vectorization (TF-IDF):** The system converts all book descriptions (features) into numerical vectors using Term Frequency-Inverse Document Frequency. This highlights unique words (like specific character names or unique topics) while down-weighting common words.\n",
                "3.  **Similarity Calculation (Cosine Similarity):** We calculate the cosine of the angle between the input book's vector and every other book's vector.\n",
                "4.  **Output:** The system returns the top $N$ books with the highest similarity scores.\n",
                "\n",
                "### Justification of design choices\n",
                "-   **Why Content-Based?** We don't have user purchase history for this specific implementation, so we cannot use Collaborative Filtering. Content-based is excellent for recommending items similar to what a user specifically asks for.\n",
                "-   **Why TF-IDF?** It is efficient and effective for text-based similarity comparisons without needing heavy deep learning compute power."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Core Implementation\n",
                "\n",
                "### Model training / inference logic\n",
                "Here we implement the vectorization and similarity matrix computation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.metrics.pairwise import linear_kernel\n",
                "\n",
                "# Initialize TF-IDF Vectorizer\n",
                "# removing english stop words like 'the', 'a', 'an'\n",
                "tfidf = TfidfVectorizer(stop_words='english')\n",
                "\n",
                "# Construct the TF-IDF Matrix\n",
                "print(\"Training TF-IDF Model...\")\n",
                "tfidf_matrix = tfidf.fit_transform(books_df['features'])\n",
                "print(f\"TF-IDF Matrix Shape: {tfidf_matrix.shape}\")\n",
                "\n",
                "# Compute Cosine Similarity Matrix\n",
                "# linear_kernel is a faster implementation of cosine_similarity for this case\n",
                "print(\"Computing Cosine Similarity Matrix...\")\n",
                "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
                "print(\"Model Training Complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Recommendation or prediction pipeline\n",
                "We define a function that takes a book title and returns the best matches."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a reverse mapping of titles to indices for fast lookup\n",
                "indices = pd.Series(books_df.index, index=books_df['Book-Title']).drop_duplicates()\n",
                "\n",
                "def recommend_book(title, cosine_sim=cosine_sim):\n",
                "    try:\n",
                "        # 1. Get the index of the book\n",
                "        if title not in indices:\n",
                "            return [f\"Book '{title}' not found in database.\"]\n",
                "        \n",
                "        idx = indices[title]\n",
                "        \n",
                "        # Handle slight edge case if duplicate titles still exist\n",
                "        if isinstance(idx, pd.Series):\n",
                "            idx = idx.iloc[0]\n",
                "\n",
                "        # 2. Get the pairwise similarity scores\n",
                "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
                "\n",
                "        # 3. Sort the books based on the similarity scores\n",
                "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
                "\n",
                "        # 4. Get the scores of the 5 most similar books (ignoring index 0 which is the book itself)\n",
                "        sim_scores = sim_scores[1:6]\n",
                "\n",
                "        # 5. Get the book indices\n",
                "        book_indices = [i[0] for i in sim_scores]\n",
                "\n",
                "        # 6. Return the top 5 most similar books\n",
                "        return books_df['Book-Title'].iloc[book_indices].tolist()\n",
                "    except Exception as e:\n",
                "        return [f\"An error occurred: {str(e)}\"]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Evaluation & Analysis\n",
                "\n",
                "### Metrics used \n",
                "Since this is an unsupervised learning task (there is no \"correct\" label), we use **Qualitative Evaluation**. We check if the recommendations make intuitive sense (e.g., if we input a Harry Potter book, do we get other fantasy books?).\n",
                "\n",
                "### Sample outputs / predictions\n",
                "Let's test the system with a few popular titles."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_books = [\n",
                "    \"Classical Mythology\",\n",
                "    \"The Fellowship of the Ring (The Lord of the Rings, Part 1)\"\n",
                "]\n",
                "\n",
                "for book in test_books:\n",
                "    print(f\"\\nRecommendations for '{book}':\")\n",
                "    recommendations = recommend_book(book)\n",
                "    for i, rec in enumerate(recommendations, 1):\n",
                "        print(f\"{i}. {rec}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Performance analysis and limitations\n",
                "-   **Performance:** The system uses `linear_kernel` which is optimized, but for very large datasets (millions of books), the $O(N^2)$ complexity of the similarity matrix could be a bottleneck.\n",
                "-   **Limitations:** \n",
                "    -   **Cold Start:** Can only recommend books that are in the dataset.\n",
                "    -   **Lack of Personalization:** It only looks at content, not user history."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Ethical Considerations & Responsible AI\n",
                "\n",
                "### Bias and fairness considerations\n",
                "-   **Representation Bias:** The dataset (`Book-Crossing`) relies on a community of users who may have specific demographic leanings. If the dataset lacks diverse authors, the recommender will fail to suggest them.\n",
                "\n",
                "### Responsible use of AI tools\n",
                "-   This tool is a supportive discovery aid. It should not be presented as an objective authority on \"good\" literature, but rather as a \"search by similarity\" tool.\n",
                "\n",
                "### Dataset limitations\n",
                "-   The data contains older books (up to 2004 in the original dump), so it will not recommend the latest 2024 bestsellers."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Conclusion & Future Scope\n",
                "\n",
                "### Summary of results\n",
                "We successfully built a Content-Based Recommendation System that suggests books based on Title, Author, and Publisher similarity. The system runs efficiently on the provided subset and gives distinct, relevant results for test inputs.\n",
                "\n",
                "### Possible improvements and extensions\n",
                "1.  **Hybrid Model:** Integrate user ratings to prioritize higher-rated books among the similar ones.\n",
                "2.  **Better NLP:** Use Description/Summary text (if available) with embeddings like BERT for deeper semantic understanding instead of just keyword matching.\n",
                "3.  **Deploy as Web App:** The logic here can be wrapped in a Streamlit app for easy user interaction (as done in `app.py`)."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}